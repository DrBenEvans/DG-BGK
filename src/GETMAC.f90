       SUBROUTINE GETMAC(maxNPOIN_PP,NPOIN_PP,IPCOM_PP,ND_PP,RHO_PP,& 
     &     UVEL_PP,VVEL_PP,PS_PP,TEMP_PP,NPOIN,ND,RHO,& 
     &     UVEL,VVEL,PS,TEMP,NGRPS,MPI_RANK_P,MPI_COMM_P) 
! 
! *** THIS ROUTINE GATHERS TOGETHER THE PROCESSOR'S NODAL MACROSCOPIC VARIABLES INTO 
! *** A SINGLE GLOBAL VECTORS FOR OUTPUT 
! 
      IMPLICIT NONE 
      INCLUDE 'mpif.h' 
! 
      INTEGER NPOIN_PP,NPOIN,IP,IG,NGRPS,IP_PP,TAG,maxNPOIN_PP 
      INTEGER IPCOM_PP(NPOIN_PP),MPI_IERR,IPT,IPCOMloc(maxNPOIN_PP) 
      INTEGER MPI_STATUS(MPI_STATUS_SIZE),FLAG(NPOIN) 
      INTEGER MPI_COMM_P,MPI_RANK_P
! 
      REAL ND_PP(NPOIN_PP),RHO_PP(NPOIN_PP),TEMP_PP(NPOIN_PP) 
      REAL UVEL_PP(NPOIN_PP),VVEL_PP(NPOIN_PP),PS_PP(NPOIN_PP) 
      REAL ND(NPOIN),RHO(NPOIN),TEMP(NPOIN),UVEL(NPOIN) 
      REAL VVEL(NPOIN),PS(NPOIN) 
      REAL NDloc(maxNPOIN_PP),RHOloc(maxNPOIN_PP),UVELloc(maxNPOIN_PP)
      REAL VVELloc(maxNPOIN_PP),PSloc(maxNPOIN_PP),TEMPloc(maxNPOIN_PP)
! 
! *** INITIALISE MACRO VECTORS 
! 	
      IF(MPI_RANK_P.EQ.0)THEN 
      CALL RFILLV(ND,NPOIN,0.0) 
      CALL RFILLV(RHO,NPOIN,0.0) 
      CALL RFILLV(UVEL,NPOIN,0.0) 
      CALL RFILLV(VVEL,NPOIN,0.0) 
      CALL RFILLV(PS,NPOIN,0.0) 
      CALL RFILLV(TEMP,NPOIN,0.0) 
      CALL IFILLV(FLAG,NPOIN,0) 
      ENDIF!LINKS WITH IF STATEMENT ON LINE 20 
!	 
      DO 1000 IG=1,NGRPS
       IF(MPI_RANK_P.EQ.IG)THEN 
       CALL MPI_SEND(NPOIN_PP,1,MPI_INTEGER,0,1,MPI_COMM_P,MPI_IERR) 
       CALL MPI_SEND(IPCOM_PP,NPOIN_PP,MPI_INTEGER,0,2,MPI_COMM_P,& 
     &            MPI_IERR) 
            CALL MPI_SEND(ND_PP,NPOIN_PP,MPI_REAL,0,3,MPI_COMM_P,& 
     &            MPI_IERR) 
            CALL MPI_SEND(RHO_PP,NPOIN_PP,MPI_REAL,0,4,MPI_COMM_P,& 
     &                   MPI_IERR) 
            CALL MPI_SEND(UVEL_PP,NPOIN_PP,MPI_REAL,0,5,MPI_COMM_P,& 
     &                   MPI_IERR) 
            CALL MPI_SEND(VVEL_PP,NPOIN_PP,MPI_REAL,0,6,MPI_COMM_P,& 
     &                   MPI_IERR) 
            CALL MPI_SEND(PS_PP,NPOIN_PP,MPI_REAL,0,7,MPI_COMM_P,& 
     &                   MPI_IERR) 
            CALL MPI_SEND(TEMP_PP,NPOIN_PP,MPI_REAL,0,8,MPI_COMM_P,& 
     &                   MPI_IERR) 
        ENDIF 
! 
        IF(MPI_RANK_P.EQ.0)THEN 
           
          CALL MPI_RECV(NPOIN_PP,1,MPI_INTEGER,IG,1,MPI_COMM_P,& 
     &         MPI_STATUS,MPI_IERR) 
! 
          CALL MPI_RECV(IPCOMloc,NPOIN_PP,MPI_INTEGER,IG,2,& 
     &          MPI_COMM_P, MPI_STATUS, MPI_IERR) 
          CALL MPI_RECV(NDloc,NPOIN_PP,MPI_REAL,IG,3,& 
     &          MPI_COMM_P, MPI_STATUS, MPI_IERR) 
          CALL MPI_RECV(RHOloc,NPOIN_PP,MPI_REAL,IG,4,& 
     &          MPI_COMM_P, MPI_STATUS, MPI_IERR) 
          CALL MPI_RECV(UVELloc,NPOIN_PP,MPI_REAL,IG,5,& 
     &          MPI_COMM_P, MPI_STATUS, MPI_IERR) 
          CALL MPI_RECV(VVELloc,NPOIN_PP,MPI_REAL,IG,6,& 
     &          MPI_COMM_P, MPI_STATUS, MPI_IERR) 
          CALL MPI_RECV(PSloc,NPOIN_PP,MPI_REAL,IG,7,& 
     &          MPI_COMM_P, MPI_STATUS, MPI_IERR) 
          CALL MPI_RECV(TEMPloc,NPOIN_PP,MPI_REAL,IG,8,& 
     &         MPI_COMM_P, MPI_STATUS, MPI_IERR) 
! 
            DO 1010 IP_PP=1,NPOIN_PP 
              IP=IPCOMloc(IP_PP)
              ND(IP)=ND(IP)+NDloc(IP_PP)
              RHO(IP)=RHO(IP)+RHOloc(IP_PP) 
              UVEL(IP)=UVEL(IP)+UVELloc(IP_PP) 
              VVEL(IP)=VVEL(IP)+VVELloc(IP_PP) 
              PS(IP)=PS(IP)+PSloc(IP_PP) 
              TEMP(IP)=TEMP(IP)+TEMPloc(IP_PP) 
              FLAG(IP)=FLAG(IP)+1 
 1010 CONTINUE 
! 
      ENDIF 
      CALL MPI_BARRIER(MPI_COMM_P,MPI_IERR) 
! 
 1000 CONTINUE 
      IF(MPI_RANK_P.EQ.0)THEN 
      DO 1020 IP=1,NPOIN 
              ND(IP)=ND(IP)/FLAG(IP) 
              RHO(IP)=RHO(IP)/FLAG(IP) 
              UVEL(IP)=UVEL(IP)/FLAG(IP) 
              VVEL(IP)=VVEL(IP)/FLAG(IP) 
              PS(IP)=PS(IP)/FLAG(IP) 
              TEMP(IP)=TEMP(IP)/FLAG(IP) 
 1020 CONTINUE 
      ENDIF
! 
      RETURN 
      END 
           
